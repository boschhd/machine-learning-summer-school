{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Perceptron Classifier from Scratch\n",
    "\n",
    "After having seen several classifiers it's our turn to implement one of them by ourselves. A perceptron is a good choice to start implementing it from scratch because it is easy to understand. Implementing algorithms from scratch allows us to gain a deeper understanding of what actually happens inside the black box.\n",
    "\n",
    "Let's start by thinking about a perceptron as a function that maps an input `X` to an output `y`. In most of the cases, `X` is a set of features $x_1$, $x_2$, ... $x_n$ put together. For instance, in image processing our features are pixel values, while in text processing some characteristics like uppercased words or part-of-speech tags (the word is a verb, or a noun) can be included as features. In order to give you an easy start, we are going to create our own data at first, and at the end you will be able to play with a bigger dataset.\n",
    "\n",
    "Let's display some random features in a table and create the data for them:\n",
    "\n",
    "Features and labels:\n",
    "\n",
    " ![table](../data/table.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define your x-matrix and your y-vector\n",
    "\n",
    "x = np.array([[2., 5.],\n",
    "              [0., 2.],\n",
    "              [2., 3.],\n",
    "              [5., 1.]])\n",
    "# Labels \n",
    "y = [1, 1, 0, 0]\n",
    "   \n",
    "print(\"x=\", x)\n",
    "print(\"y=\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at our function that maps its input vector $x$ to an output real value $f(x)$\n",
    "\n",
    "![funct](../data/funct.png)\n",
    "\n",
    "where $\\mathbf{w}$ is a vector of real-valued weights, $\\mathbf {w} \\cdot \\mathbf {x}$ is the dot product $\\sum _{i=1}^{m}w_{i}x_{i}$.\n",
    "\n",
    "After we are provided the x and y, we need to find a set of weights that can be multiplied with the features x. The result of multiplication would help us to classify the input data.\n",
    "\n",
    "The algorithm for perceptron:\n",
    "![funct](../data/perceptron-alg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the function $f(x)$ \n",
    "*** Beware the common mix-up of indices: `i` for the i-th feature or the i-th row in the data set!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w, x, threshold):\n",
    "    '''\n",
    "    w : weight vector\n",
    "    x : feature vector\n",
    "    threshold : the threshold value\n",
    "    y_hat : return value\n",
    "    \n",
    "    '''\n",
    "    ## your code, 1 line ##\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "w_tmp = np.random.randn(2)\n",
    "x_tmp = x[0]\n",
    "threshold_tmp = 0\n",
    "\n",
    "print (\"w_tmp\", w_tmp)\n",
    "print (\"x_tmp\", x_tmp)\n",
    "\n",
    "print (\"result of f(x_tmp) :\", f(w_tmp, x_tmp, threshold_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the perceptron\n",
    "It's time to build your perceptron function, remember:\n",
    "\n",
    "- Generate a weight vector $w$ and a prediction vector $\\widehat{y}$ \n",
    "- Initialize $w$\n",
    "\n",
    "Now, let's start our iterations!\n",
    "- Assign a value to $\\widehat{y}$\n",
    "- Compare $\\widehat{y}$ and $y$\n",
    "- Update weights $w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function trains a perceptron and returns \n",
    "# a weight vector and a prediction vector\n",
    "def train_perceptron(x, y, threshold, alpha, epochs): \n",
    "    \n",
    "    # Write here your contribution\n",
    "    pass\n",
    "          \n",
    "    return w, yhat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameters\n",
    "threshold = 0.0     \n",
    "alpha = 0.1   \n",
    "epochs = 50   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train perceptron\n",
    "w, y_train = train_perceptron(x, y, threshold, alpha, epochs)\n",
    "print(\"Here are my weights:\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to plot our classification. We can use our weights to plot our decision boundary.\n",
    "\n",
    "Let's consider the function $f(x)= w*x$. Please notice, that this example is deliberately designed to work even without considering a bias, we'll use that in the later example. Now, let's take a look of what happens inside this elementwise multiplication: $f(x)= w_1*x_1+w_2*x_2$.\n",
    "In order to figure out our decision boundary, we need to find at least two point that match exactly our line. \n",
    "\n",
    "- We also need the minimum and maximum coordinates in $x_1$ of all our vector points. \n",
    "\n",
    "- Now, let's set our previous equation to zero and solve regarding $x_2$. This will deliver the coordinates  $x_2$ of the minima and maxima in our hyperplane. \n",
    "\n",
    "- A Plot of a line between those two vectors would display our decision boundary\n",
    "\n",
    "\n",
    "### $x_2=\\frac{-w_1*x_1}{w_2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find min and max for x_1\n",
    "p1_x = np.min(x[:,0])\n",
    "p2_x = np.max(x[:,0])\n",
    "\n",
    "# Find coordinates in x_2\n",
    "p1_y = -w[0]*p1_x/w[1]\n",
    "p2_y = -w[0]*p2_x/w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "classification = np.linspace(1,len(w),len(w)) \n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.scatter(x[:,0], x[:,1], edgecolors=(1, 0, 0))\n",
    "ax1.plot([p1_x, p2_x], [p1_y,p2_y], lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "We need to test if those weights actually work, let's write a test function for the perceptron. \n",
    "\n",
    "**Remember!**\n",
    "\n",
    "Here we do not iterate, and do not update weights, we just need a prediction. This means only the $\\widehat{y}$-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates resulting weight form our perceptron\n",
    "# It only returns a prediction vector\n",
    "def test_perceptron(w, x, threshold):\n",
    "    \n",
    "    # Write here your contribution\n",
    "    pass\n",
    "        \n",
    "    return yhat_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost there! We just need to feed some test our perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "x_test = np.array([[1., 4.],\n",
    "              [1., 2.],\n",
    "              [4., 2.],\n",
    "              [3., 1.]])\n",
    "# Labels \n",
    "y_test = [1, 1, 0, 0]\n",
    "\n",
    "y_pred = test_perceptron(w, x_test, threshold)\n",
    "print(\"Predicted y =\", y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to compare the prediction delivered with our gold labels. Let's compute the accuracy of the model and see how does the perceptron work on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! We made it! It looks like a peceptron can classify very good our data. What about creating some more data and testing it again? For that, we can use the function `multivariate_normal` provided in `numpy.random`, this function takes as input a vector as *mean* and a matrix as *covariance matrix* and delivers a lot of random samples around the mean. The covariance matrix determines the magnitude and the main axes of the samples' distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 500\n",
    "\n",
    "class_1 = np.random.multivariate_normal([6,-6], [[1.,.5],[.5,1.]], samples)\n",
    "class_2 = np.random.multivariate_normal([2, 2], [[1.,.5],[.5,1.]], samples)\n",
    "\n",
    "x_data = np.vstack((class_1, class_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how these samples look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "ax2.scatter([class_1[:,0]], [class_1[:,1]], c=\"b\")\n",
    "ax2.scatter([class_2[:,0]], [class_2[:,1]], c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "Let's create the labels include a bias and merge all data together. The bias is just a value which is constant for all data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels\n",
    "labels_1 = np.ones((samples,1))\n",
    "labels_2 = np.zeros((samples,1))\n",
    "\n",
    "# Create bias and merge everything together\n",
    "bias = np.ones((samples*2, 1)).astype(np.float32)\n",
    "labels = np.vstack((labels_1, labels_2))\n",
    "features = np.concatenate((class_1, class_2), axis=0)\n",
    "biased = np.hstack((bias, features))\n",
    "dataset = np.hstack((biased, labels))\n",
    "\n",
    "# Shuffle data and apply a 80/20 split\n",
    "np.random.shuffle(dataset)\n",
    "split = int(len(dataset[:,0]) * 0.8)\n",
    "train = dataset[:split,:]\n",
    "test = dataset[split:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your parameters and train again to obtain the new weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters\n",
    "\n",
    "# Write here your contribution\n",
    "\n",
    "\n",
    "w, train_y = train_perceptron(train_data, train_labels, threshold, alpha, epochs)\n",
    "\n",
    "print(\"trained weight:\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just plot again our decision boundary, remember, that this time we have a bias, so our formula looks a bit different:   \n",
    "## $x_1=\\frac{-w_0-w_1*x_0}{w_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find min and max, calculate x_1 points and \n",
    "# plot a the decision boundary as we did previosly\n",
    "\n",
    "# Write here your contribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what about accuracy? If this graph is correct, we have an accuracy of 100% Yay! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = test_perceptron(w, test_data, threshold)\n",
    "pred_y = np.reshape(pred_y,(len(pred_y),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
